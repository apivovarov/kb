{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as Sagemaker endpoint and Invoke it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import yaml\n",
    "# Prepare boto3 Sagemaker client\n",
    "region = \"us-west-2\"\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "# Role to give SageMaker service permission to access your account resources (s3, etc.). Change role ARN to correct one.\n",
    "sagemaker_role = \"arn:aws:iam::345967381662:role/service-role/AmazonSageMaker-ExecutionRole-20180829T140091\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Sagemaker endpoint and deploy the model\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "#Get model from S3\n",
    "model_url = f\"s3://sagemaker-us-west-2-345967381662/stable-diffusion/text-to-image/sm_model_g5.tar.gz\"\n",
    "\n",
    "#Get SM container image (prebuilt example)\n",
    "container = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.0.1-gpu-py310-cu118-ubuntu20.04-sagemaker\"\n",
    "\n",
    "# ==== Create model ====\n",
    "model_name = \"stable-diffusion-2-1-base-g5\"\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    Containers = [{\n",
    "        \"Image\": container,\n",
    "        \"Mode\": \"SingleModel\",\n",
    "        \"ModelDataUrl\": model_url,\n",
    "    }]\n",
    ")\n",
    "print(yaml.dump(create_model_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### === Create Endpoint Config ====\n",
    "\n",
    "endpoint_config_name = \"stable-diffusion-2-1-base-g5\"\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(yaml.dump(endpoint_config_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Create Endpoint ====\n",
    "\n",
    "endpoint_name = 'stable-diffusion-2-1-base-g5'\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(yaml.dump(create_endpoint_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Check Endpoint Status ====\n",
    "desc_endpoint_response = sm_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "print(f\"EndpointStatus: {desc_endpoint_response.get('EndpointStatus', None)}\")\n",
    "print(\"==========================================================\")\n",
    "print(yaml.dump(desc_endpoint_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the Endpoint via Boto3 SageMaker Client\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "content_type = \"application/json\"\n",
    "# You can use multiple prompts in prompt array \n",
    "# if the model was compiled with batch size greater than one (or with variable batch size)\n",
    "request_body = {\n",
    "    \"prompt\": [\"a photo of an astronaut riding a horse on mars\"]\n",
    "}\n",
    "\n",
    "# Serialize data for endpoint\n",
    "payload = json.dumps(request_body)\n",
    "\n",
    "config = Config(region_name = 'us-west-2')\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\", config=config)\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "    # change to your endpoint name returned in the previous step\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload,\n",
    ")\n",
    "print(yaml.dump(response['ResponseMetadata']))\n",
    "res = response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Generated Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "for img_encoded in eval(res)[\"images\"]:\n",
    "    pred_decoded_byte = base64.decodebytes(\n",
    "        bytes(img_encoded, encoding=\"utf-8\")\n",
    "    )\n",
    "    # update H for used model edition (base - 512, regular - 768)\n",
    "    H = 512\n",
    "    pred_decoded = np.reshape(np.frombuffer(pred_decoded_byte, dtype=np.uint8), (H, H, 3))\n",
    "    plt.imshow(pred_decoded)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
